{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Deep-Learning\" data-toc-modified-id=\"Deep-Learning-1\">Deep Learning</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Neural-Networks\" data-toc-modified-id=\"Neural-Networks-1.0.1\">Neural Networks</a></span></li><li><span><a href=\"#Forward-Propagation\" data-toc-modified-id=\"Forward-Propagation-1.0.2\">Forward Propagation</a></span></li></ul></li><li><span><a href=\"#Gradient-Descent\" data-toc-modified-id=\"Gradient-Descent-1.1\">Gradient Descent</a></span></li><li><span><a href=\"#Backpropagation\" data-toc-modified-id=\"Backpropagation-1.2\">Backpropagation</a></span></li><li><span><a href=\"#Setting-up-your-Keras-and-TensorFlow-Libararies-in-Jupyter-Notebook/Lab\" data-toc-modified-id=\"Setting-up-your-Keras-and-TensorFlow-Libararies-in-Jupyter-Notebook/Lab-1.3\">Setting-up your Keras and TensorFlow Libararies in Jupyter Notebook/Lab</a></span></li><li><span><a href=\"#Creating-a-Keras-Model\" data-toc-modified-id=\"Creating-a-Keras-Model-1.4\">Creating a Keras Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-Specification\" data-toc-modified-id=\"Model-Specification-1.4.1\">Model Specification</a></span></li><li><span><a href=\"#Compiling-and-fitting-a-model\" data-toc-modified-id=\"Compiling-and-fitting-a-model-1.4.2\">Compiling and fitting a model</a></span></li></ul></li><li><span><a href=\"#Classifiction-Models\" data-toc-modified-id=\"Classifiction-Models-1.5\">Classifiction Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-Your-Model\" data-toc-modified-id=\"Using-Your-Model-1.5.1\">Using Your Model</a></span></li></ul></li><li><span><a href=\"#Model-Optimization\" data-toc-modified-id=\"Model-Optimization-1.6\">Model Optimization</a></span></li><li><span><a href=\"#Model-Validation\" data-toc-modified-id=\"Model-Validation-1.7\">Model Validation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-Summary\" data-toc-modified-id=\"Model-Summary-1.7.1\">Model Summary</a></span></li><li><span><a href=\"#Plot-Model-Score-vs-Epochs\" data-toc-modified-id=\"Plot-Model-Score-vs-Epochs-1.7.2\">Plot Model Score vs Epochs</a></span></li></ul></li><li><span><a href=\"#Model-Capacity\" data-toc-modified-id=\"Model-Capacity-1.8\">Model Capacity</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "\n",
    "### Neural Networks\n",
    "Deep learning uses especially powerful **neural networks**\n",
    "\n",
    "NN consists of 3 layers:\n",
    "1. *Input Layer* which contain the features\n",
    "2. *Output Layer* which contains the predictive variable (target)\n",
    "3. *Hidden Layer* which models interaction between features (input) and reflect it to the output layer. The more nodes it contains, the more interactions it can capture, and the more complex the computation is.\n",
    "\n",
    "<img src= \"diagram.png\" height=\"300\" width=\"300\">\n",
    "\n",
    "### Forward Propagation\n",
    "\n",
    "<img src= \"feed-forward.png\" height=\"400\" width=\"400\">\n",
    "\n",
    "As you can see from the diagram above. The outputs of the input layer are multiplied by some weights that we need to predict. Adding the products of the weights with the outputs of the input layer determines the value in the hidden layer. The same procedure occurs with the output layer. Moving from the input to hidden to output layers is called **Forward Propagation**.\n",
    "\n",
    "In order to capture non-linear behaviors between the features themselves, and the feature with the target variable, an **activation function** is used in the hidden layer. According to the function, the input values are transformed into an output that will go through the output layer. One example of activation function is **Rectified Linear Activation Function (ReLU)** which is defined as follows:\n",
    "\n",
    "$$ RELU(x)=   \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      0 \\space & x<0 \\\\\n",
    "      x & a>=0\\\\\n",
    "\\end{array} \n",
    "\\right.  $$\n",
    "\n",
    "In python you can define the function as follows:\n",
    "\n",
    "```python\n",
    "def relu(input):\n",
    "    '''Define your relu activation function here'''\n",
    "\n",
    "    output = max(input, 0)\n",
    "    \n",
    "    return(output)\n",
    "```\n",
    "\n",
    "In order to have better predictions, the number of hidden layers is increased. The more the layers the better the model, the more complex it is. Deep networks internally build represenatations of patterns in the data. It partially replaces the need for feature engineering. More deeper layers include more sophesticated representations of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "The target to is minimize the loss function (commonly RMSE). This target can be achieved by moving along the loss function for each set of weight values. The slope of the tangent line to the function decide the direction to move along the curve. Move with steps along the loss function curve and measure the slope each time until the slope is minimized. The weights corresponding to the minimum slope are the ones you choose to optimize the model. In addition, the movements steps must be controlled because moving too slow leads to slow simulations and higher computations, and moving too fast might lead us astray. Therefore, we use the **learning rate** and multiply it by the current slope. Then, subtract the result from the current weights to get the new weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "It propagates from prediction error of the output layer through the hidden layers and back to the input layer. This allows gradient descent to update all weights in neural network (by getting gradient/slope for all weights). You need to use forward propagation before updating the weights using backward propagation. Each time you generate predictions using forward propagation, you update the weights using backward propagation.\n",
    "\n",
    "The slope for wieght is product of:\n",
    "1. Node value feeding into that weight\n",
    "2. Slope of activation function for the node being fed into\n",
    "3. Slope of loss function w.r.t output node\n",
    "\n",
    "It is common to calculate slopes on only a subset of the data ('batch'). Then, use a different batch of data to calculate next update until you use all data. This is called **Stochastic Gradient Descent**\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ignore some warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries needed\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#set plotting style to 'ggplot'\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting-up your Keras and TensorFlow Libararies in Jupyter Notebook/Lab\n",
    "\n",
    "1. Create environment `dl`\n",
    "> conda create -n dl tensorflow\n",
    "\n",
    " > conda activate dl\n",
    " \n",
    "2. In this invironment only tesnorflow is install so you need to install all other libraries such as:\n",
    "pandas, numpy, sklearn, matplotlib, seaborn, keras, ...\n",
    "> pip install ---\n",
    "\n",
    "3. Re-install jupyter notebook \n",
    "> pip install jupyter notebook\n",
    "\n",
    "4. Re-install jupyter lab (if you are using it)\n",
    "> python -m pip install jupyterlab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Keras Model\n",
    "\n",
    "1. Specify model Architecture\n",
    "2. Compile the model\n",
    "3. Fit the model\n",
    "4. Make prediction\n",
    "\n",
    "### Model Specification\n",
    "\n",
    "* **`Sequential()`** each layers have nodes connected only the next layer\n",
    "* **`Dense()`** ALL nodes in previous layers are connected to ALL nodes in current layer\n",
    "\n",
    "After choosing the layer type you specify the following:\n",
    "* Number of nodes\n",
    "* activation function to be used:\n",
    "    * `\"relu\"`\n",
    "    * `\"sigmoid\"` outputs 0 or 1\n",
    "    * `\"softmax\"` ensures predictions sum to 1 so that they can interpreted as probabilities\n",
    "\n",
    "In the next example you'll predict workers wages based on characteristics like their industry, education and level of experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>union</th>\n",
       "      <th>education_yrs</th>\n",
       "      <th>experience_yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>marr</th>\n",
       "      <th>south</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.95</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.67</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.50</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wage_per_hour  union  education_yrs  experience_yrs  age  female  marr  \\\n",
       "0           5.10      0              8              21   35       1     1   \n",
       "1           4.95      0              9              42   57       1     1   \n",
       "2           6.67      0             12               1   19       0     0   \n",
       "3           4.00      0             12               4   22       0     0   \n",
       "4           7.50      0             12              17   35       0     1   \n",
       "\n",
       "   south  manufacturing  construction  \n",
       "0      0              1             0  \n",
       "1      0              1             0  \n",
       "2      0              1             0  \n",
       "3      0              0             0  \n",
       "4      0              0             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/wages.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df.drop('wage_per_hour',axis=1).values\n",
    "target = df['wage_per_hour'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Set up the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer (input layer)\n",
    "# it expects 50 features\n",
    "model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the second layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer of one node\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling and fitting a model\n",
    "\n",
    "* **`.compile()`**\n",
    "\n",
    "    * Specify the **optimizer** to control the learning rate\n",
    "        * `\"Adam\"` is usually a good choice\n",
    "        * `\"sgd\"`\n",
    "        * `\"rmsprop\"`\n",
    "    \n",
    "    * Specify the **loss function**\n",
    "        * `\"mean_squared_error\"` is a common choice for regression\n",
    "        * `\"binary_crossentropy\"`\n",
    "        * `\"categorical_crossentropy\"` useful if you have categorical variable\n",
    "    * Specify the **metrics** to be used to evaluate the model\n",
    "        * `['accuracy']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Model\n",
    "\n",
    "* **`.fit()`** Apply backpropagation and gradient descent with your data to update weights\n",
    "    * predictors\n",
    "    * target/variable\n",
    "    * **`epochs`** # of trials (going to all training data)\n",
    "    * **`steps_per_epoch`** specify the amount of pass to go through in one epoch\n",
    "    * **`verbos`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "534/534 [==============================] - 0s 190us/step - loss: 61.3830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f1e7527248>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(predictors,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiction Models\n",
    "\n",
    "* Loss function is Log Loss: \"categorical_crossentropy\"\n",
    "* Add metrics = ['accuracy'] to print accuracy at each epoch which makes it easier for model debugging\n",
    "* Output Layer does not consist of one node here. It consists of separate node for each posible outcome.\n",
    "* Change activation function of the output to 'softmax' which ensures predictions sum to 1 so that they can interpreted as probabilities\n",
    "\n",
    "\n",
    "\n",
    "In the next example we will study the **titanic dataset* and predict weather a passenger survives or not\n",
    "\n",
    "First we will convert the target variable to categories and perform **one-hot incoding** on it by implementing:\n",
    "```python\n",
    "from keras.utils import to_categorical\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>male</th>\n",
       "      <th>age_was_missing</th>\n",
       "      <th>embarked_from_cherbourg</th>\n",
       "      <th>embarked_from_queenstown</th>\n",
       "      <th>embarked_from_southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  male  age_was_missing  \\\n",
       "0         0       3  22.0      1      0   7.2500     1            False   \n",
       "1         1       1  38.0      1      0  71.2833     0            False   \n",
       "2         1       3  26.0      0      0   7.9250     0            False   \n",
       "3         1       1  35.0      1      0  53.1000     0            False   \n",
       "4         0       3  35.0      0      0   8.0500     1            False   \n",
       "\n",
       "   embarked_from_cherbourg  embarked_from_queenstown  \\\n",
       "0                        0                         0   \n",
       "1                        1                         0   \n",
       "2                        0                         0   \n",
       "3                        0                         0   \n",
       "4                        0                         0   \n",
       "\n",
       "   embarked_from_southampton  \n",
       "0                          1  \n",
       "1                          0  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>male</th>\n",
       "      <th>embarked_from_cherbourg</th>\n",
       "      <th>embarked_from_queenstown</th>\n",
       "      <th>embarked_from_southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>0.647587</td>\n",
       "      <td>0.188552</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.722783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.002015</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.391372</td>\n",
       "      <td>0.281141</td>\n",
       "      <td>0.447876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare  \\\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208   \n",
       "std      0.486592    0.836071   13.002015    1.102743    0.806057   49.693429   \n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    2.000000   22.000000    0.000000    0.000000    7.910400   \n",
       "50%      0.000000    3.000000   29.699118    0.000000    0.000000   14.454200   \n",
       "75%      1.000000    3.000000   35.000000    1.000000    0.000000   31.000000   \n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200   \n",
       "\n",
       "             male  embarked_from_cherbourg  embarked_from_queenstown  \\\n",
       "count  891.000000               891.000000                891.000000   \n",
       "mean     0.647587                 0.188552                  0.086420   \n",
       "std      0.477990                 0.391372                  0.281141   \n",
       "min      0.000000                 0.000000                  0.000000   \n",
       "25%      0.000000                 0.000000                  0.000000   \n",
       "50%      1.000000                 0.000000                  0.000000   \n",
       "75%      1.000000                 0.000000                  0.000000   \n",
       "max      1.000000                 1.000000                  1.000000   \n",
       "\n",
       "       embarked_from_southampton  \n",
       "count                 891.000000  \n",
       "mean                    0.722783  \n",
       "std                     0.447876  \n",
       "min                     0.000000  \n",
       "25%                     0.000000  \n",
       "50%                     1.000000  \n",
       "75%                     1.000000  \n",
       "max                     1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDA\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "891/891 [==============================] - 0s 122us/step - loss: 1.6747 - accuracy: 0.6027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f1e88b8e08>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Define the predictors\n",
    "predictors = df.drop(['survived'],axis=1)\n",
    "\n",
    "# Convert the target to categorical: target\n",
    "target = to_categorical(df.survived)\n",
    "\n",
    "# Save number of columns\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Set up the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(32,activation='relu',input_shape=(n_cols,)))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# 'sgd' stochastic gradient descent\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple model in 1 epoch got as accuracy of 56%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using and Saving Your Model\n",
    "You can use your model using:\n",
    "* Saving (with extension `.h5`)\n",
    "* Reloading\n",
    "* Make prediction\n",
    "* Verfiy its structure\n",
    "\n",
    "```python\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('model_file.h5')\n",
    "my_model = load_model('my_model.h5')\n",
    "predictions = my_model.predict(data_to_predict_with)\n",
    "probability_true = predictions[:,1]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Model Optimization\n",
    "\n",
    "If your model doesn't show much improvement try:\n",
    "* Changing the learning rate\n",
    "* Changing the activation function\n",
    "\n",
    "The next code will show you the effect of having 3 different learning rates from very high to very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.000001\n",
      "\n",
      "Epoch 1/1\n",
      "891/891 [==============================] - 0s 59us/step - loss: 9.2435\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "\n",
      "Epoch 1/1\n",
      "891/891 [==============================] - 0s 59us/step - loss: 2.4643\n",
      "\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "\n",
      "Epoch 1/1\n",
      "891/891 [==============================] - 0s 59us/step - loss: 32.2912\n"
     ]
    }
   ],
   "source": [
    "# Import the SGD optimizer\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Create list of learning rates: lr_to_test\n",
    "lr_to_test = [0.000001,0.01,1]\n",
    "\n",
    "# Loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    \n",
    "    # Set up the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add the first layer\n",
    "    model.add(Dense(32,activation='relu',input_shape=(n_cols,)))\n",
    "\n",
    "    # Add the output layer\n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "    \n",
    "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
    "    my_optimizer = SGD(lr=lr)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=my_optimizer,loss='categorical_crossentropy')\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(predictors,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "## Model Validation\n",
    "\n",
    "### Splitting Training Data\n",
    "* You can tell keras to use some of your data as a validation set.\n",
    "    * **`model.fit(predictors,target,validation_split=0.3)`**\n",
    "    \n",
    "### Early Stopping    \n",
    "* You can tell keras to stop epochs when the model is not imporving. This is called **Early Stopping**\n",
    "    * **`EarlyStopping(patience=2)`** stop after 2 epochs of no improvement on the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/30\n",
      "623/623 [==============================] - 0s 200us/step - loss: 1.2033 - accuracy: 0.5634 - val_loss: 0.6105 - val_accuracy: 0.6828\n",
      "Epoch 2/30\n",
      "623/623 [==============================] - 0s 56us/step - loss: 0.6613 - accuracy: 0.6501 - val_loss: 0.5656 - val_accuracy: 0.7015\n",
      "Epoch 3/30\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.6219 - accuracy: 0.6774 - val_loss: 0.5226 - val_accuracy: 0.7351\n",
      "Epoch 4/30\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.6145 - accuracy: 0.6774 - val_loss: 0.5954 - val_accuracy: 0.6978\n",
      "Epoch 5/30\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.5967 - accuracy: 0.6854 - val_loss: 0.5278 - val_accuracy: 0.7425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f1e908cdc8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import EarlyStopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors,target,validation_split=0.3,epochs=30,\n",
    "          callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer stopped after 5 epochs\n",
    "\n",
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 100)               1100      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,402\n",
      "Trainable params: 11,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Model Score vs Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/10\n",
      "623/623 [==============================] - 0s 96us/step - loss: 0.6051 - accuracy: 0.6838 - val_loss: 0.5393 - val_accuracy: 0.7127\n",
      "Epoch 2/10\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.5884 - accuracy: 0.7014 - val_loss: 0.7022 - val_accuracy: 0.6493\n",
      "Epoch 3/10\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.5696 - accuracy: 0.7175 - val_loss: 0.4983 - val_accuracy: 0.7687\n",
      "Epoch 4/10\n",
      "623/623 [==============================] - 0s 102us/step - loss: 0.5474 - accuracy: 0.7271 - val_loss: 0.4823 - val_accuracy: 0.7687\n",
      "Epoch 5/10\n",
      "623/623 [==============================] - 0s 59us/step - loss: 0.6175 - accuracy: 0.7111 - val_loss: 0.4822 - val_accuracy: 0.7537\n",
      "Epoch 6/10\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.6117 - accuracy: 0.7207 - val_loss: 0.4809 - val_accuracy: 0.7687\n",
      "Epoch 7/10\n",
      "623/623 [==============================] - 0s 62us/step - loss: 0.6066 - accuracy: 0.7047 - val_loss: 0.4832 - val_accuracy: 0.7649\n",
      "Epoch 8/10\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.5598 - accuracy: 0.7335 - val_loss: 0.4719 - val_accuracy: 0.7537\n",
      "Epoch 9/10\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.5390 - accuracy: 0.7496 - val_loss: 0.4664 - val_accuracy: 0.7761\n",
      "Epoch 10/10\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.5271 - accuracy: 0.7319 - val_loss: 0.4571 - val_accuracy: 0.7687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Validation score')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_tr = model.fit(predictors,target,validation_split=0.3,epochs=10)\n",
    "\n",
    "plt.plot(model_tr.history['val_loss'], 'r')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Capacity\n",
    "\n",
    "**Model Capacity** is model's ability to capture important features from the data.\n",
    "\n",
    "**Work flow for optimizing model capacity**:\n",
    "* Start with a small network\n",
    "* Get the validation score\n",
    "* Keep increasing capacity (more layers, nodes, .. etc) until validation score no longer improves\n",
    "------------------\n",
    "\n",
    "## Predicting on Test Data\n",
    "\n",
    "* Use sklearn to split data to train and test\n",
    "* fit and transform `X_train` (if using and kind of transformation ex. scaling)\n",
    "* transform `y_train`\n",
    "* Use **`predict_classes`**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "## Evaluating Model Performance\n",
    "\n",
    "Similar to `sklearn`\n",
    "\n",
    "* **`.metrics_names`** to get the metrics names currently in the model\n",
    "* You can also import other metrices (from sklearn)\n",
    "* **`.evaluate()`** test data\n",
    "* **`.predict`** & **`.predict_classes`** to get predictions\n",
    "* compare between Y_test and Y_predict using the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "y_predict = model.predict_classes(X_test)\n",
    "confusion_matrix(y_test,y_predict)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "## Examples\n",
    "\n",
    "**Images Example**\n",
    "\n",
    "In the next example we will work with the MNIST dataset which consists of 28x28 grid images flattened to 784 values for each image. Each image shows a digit. We will create a deep learning model to predicts the digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...    775    776   777  \\\n",
       "0    5    0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...  0.608  0.609  0.61   \n",
       "1    4    0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000  0.000  0.00   \n",
       "2    3    0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000  0.000  0.00   \n",
       "3    0    0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000  0.000  0.00   \n",
       "4    2    0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000  0.000  0.00   \n",
       "\n",
       "     778    779    780    781    782    783    784  \n",
       "0  0.611  0.612  0.613  0.614  0.615  0.616  0.617  \n",
       "1  0.000  0.000  0.000  0.000  0.000  0.000  0.000  \n",
       "2  0.000  0.000  0.000  0.000  0.000  0.000  0.000  \n",
       "3  0.000  0.000  0.000  0.000  0.000  0.000  0.000  \n",
       "4  0.000  0.000  0.000  0.000  0.000  0.000  0.000  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/MNIST.csv',header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    4\n",
       "2    3\n",
       "3    0\n",
       "4    2\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(0,axis=1).values\n",
    "y = to_categorical(df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.1  , 0.2  , ..., 0.615, 0.616, 0.617],\n",
       "       [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "       ...,\n",
       "       [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , ...,   nan,   nan,   nan]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1087 samples, validate on 466 samples\n",
      "Epoch 1/30\n",
      "1087/1087 [==============================] - 0s 179us/step - loss: 31.8023 - accuracy: 0.3698 - val_loss: nan - val_accuracy: 0.5107\n",
      "Epoch 2/30\n",
      "1087/1087 [==============================] - 0s 85us/step - loss: 5.2498 - accuracy: 0.6449 - val_loss: nan - val_accuracy: 0.6052\n",
      "Epoch 3/30\n",
      "1087/1087 [==============================] - 0s 100us/step - loss: 2.5048 - accuracy: 0.7424 - val_loss: nan - val_accuracy: 0.6459\n",
      "Epoch 4/30\n",
      "1087/1087 [==============================] - 0s 94us/step - loss: 1.4912 - accuracy: 0.7939 - val_loss: nan - val_accuracy: 0.6524\n",
      "Epoch 5/30\n",
      "1087/1087 [==============================] - 0s 94us/step - loss: 0.9321 - accuracy: 0.8537 - val_loss: nan - val_accuracy: 0.6824\n",
      "Epoch 6/30\n",
      "1087/1087 [==============================] - 0s 95us/step - loss: 0.6079 - accuracy: 0.8859 - val_loss: nan - val_accuracy: 0.6781\n",
      "Epoch 7/30\n",
      "1087/1087 [==============================] - 0s 92us/step - loss: 0.3783 - accuracy: 0.9080 - val_loss: nan - val_accuracy: 0.6717\n",
      "Epoch 8/30\n",
      "1087/1087 [==============================] - 0s 132us/step - loss: 0.2684 - accuracy: 0.9292 - val_loss: nan - val_accuracy: 0.6996\n",
      "Epoch 9/30\n",
      "1087/1087 [==============================] - 0s 97us/step - loss: 0.2069 - accuracy: 0.9466 - val_loss: nan - val_accuracy: 0.6953\n",
      "Epoch 10/30\n",
      "1087/1087 [==============================] - 0s 100us/step - loss: 0.1332 - accuracy: 0.9577 - val_loss: nan - val_accuracy: 0.6910\n",
      "Epoch 11/30\n",
      "1087/1087 [==============================] - 0s 96us/step - loss: 0.1031 - accuracy: 0.9715 - val_loss: nan - val_accuracy: 0.7103\n",
      "Epoch 12/30\n",
      "1087/1087 [==============================] - 0s 89us/step - loss: 0.0775 - accuracy: 0.9752 - val_loss: nan - val_accuracy: 0.7039\n",
      "Epoch 13/30\n",
      "1087/1087 [==============================] - 0s 99us/step - loss: 0.0735 - accuracy: 0.9733 - val_loss: nan - val_accuracy: 0.7082\n",
      "Epoch 14/30\n",
      "1087/1087 [==============================] - 0s 107us/step - loss: 0.0513 - accuracy: 0.9798 - val_loss: nan - val_accuracy: 0.7275\n",
      "Epoch 15/30\n",
      "1087/1087 [==============================] - 0s 163us/step - loss: 0.0442 - accuracy: 0.9880 - val_loss: nan - val_accuracy: 0.7253\n",
      "Epoch 16/30\n",
      "1087/1087 [==============================] - 0s 137us/step - loss: 0.0538 - accuracy: 0.9807 - val_loss: nan - val_accuracy: 0.7318\n",
      "Epoch 17/30\n",
      "1087/1087 [==============================] - 0s 100us/step - loss: 0.0352 - accuracy: 0.9862 - val_loss: nan - val_accuracy: 0.7275\n",
      "Epoch 18/30\n",
      "1087/1087 [==============================] - 0s 97us/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: nan - val_accuracy: 0.7296\n",
      "Epoch 19/30\n",
      "1087/1087 [==============================] - 0s 111us/step - loss: 0.0204 - accuracy: 0.9917 - val_loss: nan - val_accuracy: 0.7253\n",
      "Epoch 20/30\n",
      "1087/1087 [==============================] - 0s 172us/step - loss: 0.0175 - accuracy: 0.9926 - val_loss: nan - val_accuracy: 0.7382\n",
      "Epoch 21/30\n",
      "1087/1087 [==============================] - 0s 119us/step - loss: 0.0144 - accuracy: 0.9926 - val_loss: nan - val_accuracy: 0.7296\n",
      "Epoch 22/30\n",
      "1087/1087 [==============================] - 0s 106us/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: nan - val_accuracy: 0.7318\n",
      "Epoch 23/30\n",
      "1087/1087 [==============================] - 0s 102us/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: nan - val_accuracy: 0.7318\n",
      "Epoch 24/30\n",
      "1087/1087 [==============================] - 0s 106us/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: nan - val_accuracy: 0.7339\n",
      "Epoch 25/30\n",
      "1087/1087 [==============================] - 0s 96us/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: nan - val_accuracy: 0.7339\n",
      "Epoch 26/30\n",
      "1087/1087 [==============================] - 0s 96us/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: nan - val_accuracy: 0.7382\n",
      "Epoch 27/30\n",
      "1087/1087 [==============================] - 0s 93us/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: nan - val_accuracy: 0.7403\n",
      "Epoch 28/30\n",
      "1087/1087 [==============================] - 0s 95us/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: nan - val_accuracy: 0.7361\n",
      "Epoch 29/30\n",
      "1087/1087 [==============================] - 0s 95us/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: nan - val_accuracy: 0.7403\n",
      "Epoch 30/30\n",
      "1087/1087 [==============================] - 0s 93us/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: nan - val_accuracy: 0.7382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f1e8fa05c8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "model.add(Dense(50, activation='relu', input_shape = (784,)))\n",
    "\n",
    "\n",
    "# Add the second hidden layer\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X,y,validation_split=0.3,epochs=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "76.9676px",
    "width": "159.988px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "164.988px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
